authoring_schema_version: "1.0.0"
mcp_spec_revision: "2025-11-25"

artifact:
  meta:
    version: "1.0.0"
    schema: "mcp.protocol/v1"
    id: "testing.test_implementation"
    title: "Test Implementation"
    description: "Rules for creating production-ready tests (unit/integration/e2e) with traceable evidence."
    enforce: true
    tags: ["testing", "quality"]

  content:
    related_doctrine: "enterprise.canonical_execution"
    applies_to: ["repo://*"]
    directives:
      - id: "tests_for_new_behavior"
        level: "required"
        statement: "When new production behavior is implemented, corresponding tests MUST be added or updated to cover it."
        rationale: "Prevents regressions and ensures behavior is executable and verifiable."
        verification: "Test changes exist and fail without the implementation, pass with the implementation."

      - id: "select_appropriate_test_types"
        level: "required"
        statement: "Test coverage MUST be appropriate for the change: unit tests for business logic, integration tests for cross-component behavior, API tests for endpoints/contracts, E2E tests for critical workflows, and security tests for security-sensitive behavior."
        rationale: "Different failure modes require different test levels; unit-only testing is insufficient for cross-boundary changes."
        verification: "Worklog identifies the chosen test levels and links them to the change scope."

      - id: "pytest_naming_and_structure"
        level: "recommended"
        statement: "For Python projects, tests SHOULD follow pytest naming conventions (test_*.py, test_* functions) and be organized by test type."
        rationale: "Improves discoverability and ensures CI collection works as expected."
        verification: "Tests run under pytest without manual collection tweaks."

      - id: "preserve_repo_test_conventions"
        level: "required"
        statement: "When a repo already defines test conventions (markers, directory layout, fixtures pattern, test runner scripts), changes MUST follow those conventions; do not introduce a parallel testing style."
        rationale: "Parallel conventions create fragmented suites and inconsistent CI behavior."
        verification: "New tests match existing conventions and execute via the repo's standard test commands."

      - id: "coverage_target"
        level: "required"
        statement: "If coverage measurement is configured (or feasible via repo-standard tooling), new/changed production code MUST meet the repo's coverage threshold; if no threshold exists, treat 80% coverage of new/changed paths as the minimum baseline unless explicitly waived."
        rationale: "Coverage is an enforcement mechanism for regression prevention; v2 required an 80% minimum baseline."
        verification: "Coverage report meets the configured threshold (or shows >=80% for new/changed paths) and is recorded as evidence."

      - id: "unit_tests_no_external_side_effects"
        level: "required"
        statement: "Unit tests MUST not rely on real external services (network calls, real databases, real cloud APIs) and MUST not create persistent side effects; use mocks/fakes/fixtures instead."
        rationale: "External coupling makes unit tests flaky and slow and breaks repeatability in CI."
        verification: "Unit tests run offline and do not require external credentials or services."

      - id: "integration_tests_isolated_non_prod"
        level: "required"
        statement: "Integration/E2E tests MUST run against isolated non-production resources (eg ephemeral containers, test databases) and MUST never target production endpoints or production data."
        rationale: "Prevents data corruption and ensures test runs are safe and repeatable."
        verification: "Test config clearly targets non-prod resources; no production hostnames/credentials are used."

      - id: "async_code_requires_async_tests"
        level: "required"
        statement: "For async production code paths, tests MUST exercise them using the repo's async test strategy (eg pytest-asyncio) and MUST not hide async bugs behind sync wrappers."
        rationale: "Async correctness depends on event-loop semantics, cancellation, timeouts, and concurrency behaviour."
        verification: "Async paths are covered by async tests and run successfully under the configured async runner."

      - id: "deterministic_tests"
        level: "required"
        statement: "Tests MUST be deterministic and must not rely on execution order or hidden global state."
        rationale: "Flaky tests erode trust and block reliable delivery."
        verification: "Re-running tests yields consistent results."

      - id: "test_data_management"
        level: "required"
        statement: "Tests MUST manage their data lifecycle (setup and teardown) so repeated runs are clean; tests must not leak state between cases."
        rationale: "State leakage is a primary cause of order-dependent failures."
        verification: "Repeated runs (including subset reruns) pass consistently without manual cleanup."

      - id: "assertions_must_be_meaningful"
        level: "required"
        statement: "Tests MUST contain meaningful assertions; superficial assertions (eg only 'assert True' / only 'not None' without behavioural checks) are prohibited."
        rationale: "Low-signal tests provide false confidence and do not prevent regressions."
        verification: "Assertions validate business outcomes, contracts, and error behaviour relevant to the change."

      - id: "evidence_for_test_runs"
        level: "required"
        statement: "When reporting test completion, evidence MUST include the exact test command(s) run, exit status, and the relevant pass/fail output excerpt."
        rationale: "Ensures test claims are auditable and repeatable across sessions and agents."
        verification: "Evidence includes command, exit status, and key output lines for each test run."

      - id: "production_validation_is_separate"
        level: "required"
        statement: "If a repository defines a production validation suite standard, it MUST be followed for runtime validation (do not substitute unit-test mocks for production validation)."
        rationale: "Runtime validation requirements (real resources / real HTTP) differ from unit testing strategies."
        verification: "Production validation uses the repository's validation suite pattern when required."

    inputs: []
    outputs: []
    notes:
      - "This protocol covers test implementation practices. Runtime production validation is governed by validation protocols (eg validation.real_resources_only, validation.api_real_http)."
    conflicts: []

  governance:
    owners: ["au-sys"]
    status: "draft"
    changeLog:
      - "Migrated from v2 009-PROTOCOL-Test_Implementation-v1.0.0.yaml; extracted enforceable testing directives."

  traceability:
    raw_ref: "repo://docs/implementation/instructions/v2/009-PROTOCOL-Test_Implementation-v1.0.0.yaml"
